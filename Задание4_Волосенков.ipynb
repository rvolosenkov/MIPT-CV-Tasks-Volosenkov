{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78bf0eb",
   "metadata": {},
   "source": [
    "# Компьютерное зрение. Базовый курс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3618d6",
   "metadata": {},
   "source": [
    "## Аугментация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fa9f9",
   "metadata": {},
   "source": [
    "#### Условие"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7ba5b",
   "metadata": {},
   "source": [
    "**Дано:** выборка идеально растеризованных страниц документов.\n",
    "\n",
    "**Необходимо:**\n",
    "\n",
    "* Сгенерировать «фотореалистичную» выборку изображений, имитирующих фотографии страниц этих документов, лежащих на произвольных поверхностях. Размер получаемой в итоге выборки должен в 10 раз превышать исходную.\n",
    "\n",
    "* Прислать исходный код алгоритма аугментации и ссылку на полученную в результате выборку. Скорость работы алгоритма не оценивается. Срок – до 21 марта.\n",
    "\n",
    "Рекомендуется применять к изображениям различные преобразования, ставящие своей целью сымитировать физический процесс регистрации страницы документа камерой, такие как:\n",
    "\n",
    "* проективное преобразование,\n",
    "\n",
    "* добавление текстур поверхности и бумаги\n",
    "\n",
    "* дефектов печати,\n",
    "\n",
    "* шумов (и шумового фильтра!),\n",
    "\n",
    "* освещения (бликов, теней, ...),\n",
    "\n",
    "* эффекта глубины резкости,\n",
    "\n",
    "т.е. всего, что добавит схожести с реальными фотографиями этих документов (полезно вспомнить материал лекции №2).\n",
    "\n",
    "Разрешается использовать внешние библиотеки для реализации отдельных этапов аугментаций. Готовые программы для 3D моделирования использовать нельзя!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249e433",
   "metadata": {},
   "source": [
    "#### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ca5b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_NUMBER = 10\n",
    "SAMPLES_NUMBER = 10\n",
    "MIN_PERSPECTIVE_DEFLECTION = 0\n",
    "MAX_PERSPECTIVE_DEFLECTION = 200\n",
    "DEFLECTION_NUMBER = 8\n",
    "NUM_CHANNELS = 3\n",
    "MIN_COMPONENT_VALUE = 0\n",
    "MAX_COMPONENT_VALUE = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301c7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a56975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewImage(image, name_of_window):\n",
    "    cv2.namedWindow(name_of_window, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name_of_window, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e31bea6",
   "metadata": {},
   "source": [
    "Для создания наиболее правдоподобного эффекта регистрации страниц документов камерой применим несколько преобразований над исходными изображениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733da119",
   "metadata": {},
   "source": [
    "1. Текстура мятой бумаги\n",
    "\n",
    "На каждое изображение наложим одно (выбранное случайным образом из двух предложенных) изображение мятой бумаги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed2795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crumpled = [cv2.imread(\"Crumpled\" + str(number) + \".png\", cv2.IMREAD_COLOR) for number in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fc051a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_crumpled(image):\n",
    "    height, width = image.shape[:2]\n",
    "    paper = cv2.resize(crumpled[np.random.randint(2)], (width, height))\n",
    "    result = 0.4 * paper + 0.6 * image\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d6534",
   "metadata": {},
   "source": [
    "2. Освещение\n",
    "\n",
    "Сымитируем 4 возможных варианта освещения документа с помощью радиального градиента. Между собой упорядочим их в порядке возрастания эффекта: первый вариант - отсутствие освещения, четвертый вариант - ярко выраженное светлое пятно (как от вспышки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3aa1771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_highlight(intensity):\n",
    "    curr_highlight = np.array([30 + intensity*3])\n",
    "    for i in range(1500):\n",
    "        new_highlight = np.full((2*i+3, 2*i+3), 29 + intensity*3 - i // (20 - intensity))\n",
    "        new_highlight[1:-1, 1:-1] = curr_highlight\n",
    "        curr_highlight = new_highlight\n",
    "    return curr_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70babfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "highlights = [np.full((3001, 3001), 0)]\n",
    "for intensity in range(13, 16):\n",
    "    highlights.append(generate_highlight(intensity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb1fbcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_highlight(image, highlights):\n",
    "    highlight = highlights[np.random.randint(0, 4)]\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    highlight_size = highlight.shape[0]\n",
    "    new_image = image.astype(np.int32).transpose((2, 0, 1))\n",
    "    new_first = highlight.copy()\n",
    "    new_first[((highlight_size - height) // 2):((highlight_size - height) // 2 + height), ((highlight_size - width) // 2):((highlight_size - width) // 2 + width)] += new_image[0]\n",
    "    new_second = highlight.copy()\n",
    "    new_second[((highlight_size - height) // 2):((highlight_size - height) // 2 + height), ((highlight_size - width) // 2):((highlight_size - width) // 2 + width)] += new_image[1]\n",
    "    new_third = highlight.copy()\n",
    "    new_third[((highlight_size - height) // 2):((highlight_size - height) // 2 + height), ((highlight_size - width) // 2):((highlight_size - width) // 2 + width)] += new_image[2]\n",
    "    new_image[0] = new_first[((highlight_size - height) // 2):((highlight_size - height) // 2 + height), ((highlight_size - width) // 2):((highlight_size - width) // 2 + width)].clip(MIN_COMPONENT_VALUE, MAX_COMPONENT_VALUE)\n",
    "    new_image[1] = new_second[((highlight_size - height) // 2):((highlight_size - height) // 2 + height), ((highlight_size - width) // 2):((highlight_size - width) // 2 + width)].clip(MIN_COMPONENT_VALUE, MAX_COMPONENT_VALUE)\n",
    "    new_image[2] = new_third[((highlight_size - height) // 2):((highlight_size - height) // 2 + height), ((highlight_size - width) // 2):((highlight_size - width) // 2 + width)].clip(MIN_COMPONENT_VALUE, MAX_COMPONENT_VALUE)\n",
    "    new_image = new_image.astype('uint8').transpose((1, 2, 0))\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850d2a8",
   "metadata": {},
   "source": [
    "3. Имитация трясущейся камеры\n",
    "\n",
    "Используем размытие по Гауссу со случайно заданными параметрами $\\sigma_x$ и $\\sigma_y$ (берутся из равномерного распределения на отрезке $[0, 4]$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aea18866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_blur(image):\n",
    "    return cv2.GaussianBlur(src=image, ksize=(0, 0), sigmaX=np.random.rand()*4, sigmaY=np.random.rand()*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f970b56",
   "metadata": {},
   "source": [
    "4. Тень\n",
    "\n",
    "Каждому \"листу бумаги\" для придания объема добавим заранее заготовленную тень."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1effdbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow = cv2.imread('Shadow.png', cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae761396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shadow(image):\n",
    "    height, width = image.shape[:2]\n",
    "    curr_shadow = cv2.resize(shadow, (width + 40, height + 40))\n",
    "    curr_shadow[20:-20, 20:-20, :] = image\n",
    "    return curr_shadow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9bbd3",
   "metadata": {},
   "source": [
    "5. Перспектива\n",
    "\n",
    "Наконец, для создания эффектов \"документ лежит на столе\" и \"документ висит на стене\" воспользуемся преобразованиями перспективы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6371e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_perspective(image):\n",
    "    height, width = image.shape[:2]\n",
    "    pts1 = np.float32([[0, 0], [width, 0],\n",
    "                       [0, height], [width, height]])\n",
    "    deflections = np.random.randint(MIN_PERSPECTIVE_DEFLECTION, MAX_PERSPECTIVE_DEFLECTION, DEFLECTION_NUMBER) * np.random.randint(2, size=8)\n",
    "    deflections[0], deflections[1] = max(deflections[0], deflections[1]), min(deflections[0], deflections[1])\n",
    "    pts2 = np.float32([[deflections[0], deflections[2]], [width - deflections[0], deflections[3]],\n",
    "                       [deflections[1], height - deflections[2]], [width - deflections[1], height - deflections[3]]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    result = cv2.warpPerspective(image, matrix, (width, height), borderValue=(MAX_COMPONENT_VALUE, MAX_COMPONENT_VALUE, MAX_COMPONENT_VALUE))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae0fbb",
   "metadata": {},
   "source": [
    "Итоговая функция, искажающая изображение и создающая эффект бумажного документа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5498642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort_image(image, image_number, number):\n",
    "    for i in range(number):\n",
    "        crumpled_image = make_crumpled(image)\n",
    "        image_with_highlight = add_highlight(crumpled_image, highlights)\n",
    "        image_with_blur = add_blur(image_with_highlight)\n",
    "        image_with_shadow = add_shadow(image_with_blur)\n",
    "        result = add_perspective(image_with_shadow)\n",
    "        cv2.imwrite('./dataset/' + str(image_number) + '_' + str(i) + '.png', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49b305c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(IMAGES_NUMBER):\n",
    "    image = cv2.imread('./sources/' + str(i + 1) + '.png', cv2.IMREAD_COLOR)\n",
    "    distort_image(image, i + 1, SAMPLES_NUMBER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
