{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "crude-armor",
   "metadata": {},
   "source": [
    "# Компьютерное зрение. Базовый курс"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-increase",
   "metadata": {},
   "source": [
    "## Алгоритмы восстановления изображений из CFA (demosaicing algorithms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-induction",
   "metadata": {},
   "source": [
    "### Алгоритм Variable Number of Gradients (VNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-vector",
   "metadata": {},
   "source": [
    "#### Условие"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-affair",
   "metadata": {},
   "source": [
    "**Дано:** исходное изображение (оригинал, reference) и соответствующее ему полутоновое изображение матрицы Байера.\n",
    "\n",
    "**Необходимо:**\n",
    "\n",
    "* реализовать один из алгоритмов demosaicing-а (в данной работе выбран алгоритм `VNG`);\n",
    "\n",
    "* восстановить с его помощью цветное изображение из полутонового;\n",
    "\n",
    "* проанализировать полученное изображение и сделать вывод, во сколько раз снижается разрешение восстановленного изображения по сравнению с оригиналом;\n",
    "\n",
    "* вычислить метрику `PSNR` между оригиналом и полученным изображением (для яркости);\n",
    "\n",
    "* оценить время работы алгоритма (сек/мегапиксель)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-xerox",
   "metadata": {},
   "source": [
    "#### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-junction",
   "metadata": {},
   "source": [
    "Для работы с изображениями (методы, необходимые для чтения изображения из файла, записи изображения в файл и отображения изображения на экране) воспользуемся библиотекой `OpenCV`, а для более быстрой и эффективной работы с массивами - библиотекой `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worthy-franchise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:48:50.564447Z",
     "start_time": "2021-10-21T13:48:50.351278Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-float",
   "metadata": {},
   "source": [
    "Загрузим и сохраним полутоновое и оригинальное изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "collectible-isaac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:48:51.837426Z",
     "start_time": "2021-10-21T13:48:51.746634Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073, 4176, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgb_cfa = cv2.imread('RGB_CFA.bmp', cv2.IMREAD_COLOR)\n",
    "rgb_cfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dental-caution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:48:55.273547Z",
     "start_time": "2021-10-21T13:48:55.269495Z"
    }
   },
   "outputs": [],
   "source": [
    "def viewImage(image, name_of_window):\n",
    "    cv2.namedWindow(name_of_window, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name_of_window, image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "turned-caribbean",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:48:57.889722Z",
     "start_time": "2021-10-21T13:48:56.634891Z"
    }
   },
   "outputs": [],
   "source": [
    "viewImage(rgb_cfa,'RGB_CFA.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "meaning-beach",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:48:59.257494Z",
     "start_time": "2021-10-21T13:48:59.210577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2073, 4176, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_img = cv2.imread('Original.bmp', cv2.IMREAD_COLOR)\n",
    "orig_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indoor-appeal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:04.469586Z",
     "start_time": "2021-10-21T13:49:00.920354Z"
    }
   },
   "outputs": [],
   "source": [
    "viewImage(orig_img,'Original.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-threat",
   "metadata": {},
   "source": [
    "Теперь можно приступать к реализации самого алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-devon",
   "metadata": {},
   "source": [
    "\"For each pixel, we recover the missing color components as follows.\n",
    "\n",
    "First, a set of gradients is determined from the color values in the $5 \\times 5$ neighborhood centered at the pixel under consideration. Each gradient corresponds to a different direction.\n",
    "\n",
    "Second, for each set of gradients, a threshold value is determined, and the threshold is used to select a subset of gradients. Low-valued gradients indicate pixels having similar color values whereas high-valued gradients would be expected in regions of the image where there are many fine details or sharp edges.\n",
    "\n",
    "Third, the subset of gradients is used to locate regions of pixels that are most like the pixel under consideration. Note that the pixels in the identified regions can lie in more than one direction from the pixel under consideration, in contrast to previous work where color values located in only a single direction are used for interpolation.\n",
    "\n",
    "The pixels in the regions are then weighted and summed to determine the average difference between the color of the actual measured center pixel value and the missing color.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aware-affiliation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:08.783039Z",
     "start_time": "2021-10-21T13:49:08.770810Z"
    }
   },
   "outputs": [],
   "source": [
    "k1 = 1.5\n",
    "k2 = 0.5\n",
    "min_component_value = 0\n",
    "max_component_value = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coral-acting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:10.236716Z",
     "start_time": "2021-10-21T13:49:10.209905Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_gradients(image_part):\n",
    "    grad_n = (abs(image_part[0][1] - image_part[2][1]) +\\\n",
    "              abs(image_part[1][1] - image_part[3][1]) +\\\n",
    "              abs(image_part[0][3] - image_part[2][3]) +\\\n",
    "              abs(image_part[1][3] - image_part[3][3])) / 2 +\\\n",
    "              abs(image_part[0][2] - image_part[2][2]) +\\\n",
    "              abs(image_part[1][2] - image_part[3][2])\n",
    "\n",
    "    grad_e = (abs(image_part[1][4] - image_part[1][2]) +\\\n",
    "              abs(image_part[1][3] - image_part[1][1]) +\\\n",
    "              abs(image_part[3][4] - image_part[3][2]) +\\\n",
    "              abs(image_part[3][3] - image_part[3][1])) / 2 +\\\n",
    "              abs(image_part[2][4] - image_part[2][2]) +\\\n",
    "              abs(image_part[2][3] - image_part[2][1])\n",
    "\n",
    "    grad_s = (abs(image_part[4][1] - image_part[2][1]) +\\\n",
    "              abs(image_part[1][1] - image_part[3][1]) +\\\n",
    "              abs(image_part[4][3] - image_part[2][3]) +\\\n",
    "              abs(image_part[1][3] - image_part[3][3])) / 2 +\\\n",
    "              abs(image_part[4][2] - image_part[2][2]) +\\\n",
    "              abs(image_part[1][2] - image_part[3][2])\n",
    "\n",
    "    grad_w = (abs(image_part[1][0] - image_part[1][2]) +\\\n",
    "              abs(image_part[1][3] - image_part[1][1]) +\\\n",
    "              abs(image_part[3][0] - image_part[3][2]) +\\\n",
    "              abs(image_part[3][3] - image_part[3][1])) / 2 +\\\n",
    "              abs(image_part[2][0] - image_part[2][2]) +\\\n",
    "              abs(image_part[2][3] - image_part[2][1])\n",
    "\n",
    "    grad_ne = abs(image_part[1][3] - image_part[3][1]) +\\\n",
    "              abs(image_part[0][4] - image_part[2][2]) +\\\n",
    "              abs(image_part[0][3] - image_part[2][1]) +\\\n",
    "              abs(image_part[1][4] - image_part[3][2])\n",
    "\n",
    "    grad_se = abs(image_part[3][3] - image_part[1][1]) +\\\n",
    "              abs(image_part[4][4] - image_part[2][2]) +\\\n",
    "              abs(image_part[3][4] - image_part[1][2]) +\\\n",
    "              abs(image_part[4][3] - image_part[2][1])\n",
    "\n",
    "    grad_sw = abs(image_part[4][0] - image_part[2][2]) +\\\n",
    "              abs(image_part[3][1] - image_part[1][3]) +\\\n",
    "              abs(image_part[3][0] - image_part[1][2]) +\\\n",
    "              abs(image_part[4][1] - image_part[2][3])\n",
    "\n",
    "    grad_nw = abs(image_part[0][0] - image_part[2][2]) +\\\n",
    "              abs(image_part[1][1] - image_part[3][3]) +\\\n",
    "              abs(image_part[1][0] - image_part[3][2]) +\\\n",
    "              abs(image_part[0][1] - image_part[2][3])\n",
    "\n",
    "    return dict(zip(['grad_n', 'grad_e', 'grad_s', 'grad_w', 'grad_ne', 'grad_se', 'grad_sw', 'grad_nw'],\n",
    "                    [grad_n, grad_e, grad_s, grad_w, grad_ne, grad_se, grad_sw, grad_nw]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saving-network",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:13.239917Z",
     "start_time": "2021-10-21T13:49:13.222114Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_direction_keys(image_part):\n",
    "    grad_dict = get_gradients(image_part)\n",
    "    min_grad, max_grad = min(grad_dict.values()), max(grad_dict.values())\n",
    "    T = k1 * min_grad + k2 * (min_grad + max_grad)\n",
    "    grad_dict = {k: v for k, v in grad_dict.items() if v < T}\n",
    "    return list(get_gradients(image_part).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vocal-holiday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:16.289276Z",
     "start_time": "2021-10-21T13:49:16.268567Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_blue_red_components(image_part):\n",
    "    keys = get_direction_keys(image_part)\n",
    "\n",
    "    above_center_comp_sum = 0\n",
    "    center_comp_sum = 0\n",
    "    under_center_comp_sum = 0\n",
    "\n",
    "    if 'grad_n' in keys:\n",
    "        above_center_comp_sum += image_part[1][2]\n",
    "        center_comp_sum += (image_part[0][2] + image_part[2][2]) / 2\n",
    "        under_center_comp_sum += (image_part[0][1] + image_part[0][3] +\\\n",
    "                  image_part[2][1] + image_part[2][3]) / 4\n",
    "\n",
    "    if 'grad_e' in keys:\n",
    "        above_center_comp_sum += (image_part[1][2] + image_part[1][4] +\\\n",
    "                  image_part[3][2] + image_part[3][4]) / 4\n",
    "        center_comp_sum += (image_part[2][4] + image_part[2][2]) / 2\n",
    "        under_center_comp_sum += image_part[2][3]\n",
    "\n",
    "    if 'grad_s' in keys:\n",
    "        above_center_comp_sum += image_part[3][2]\n",
    "        center_comp_sum += (image_part[4][2] + image_part[2][2]) / 2\n",
    "        under_center_comp_sum += (image_part[4][1] + image_part[4][3] +\\\n",
    "                  image_part[2][1] + image_part[2][3]) / 4\n",
    "\n",
    "    if 'grad_w' in keys:\n",
    "        above_center_comp_sum += (image_part[1][2] + image_part[1][0] +\\\n",
    "                  image_part[3][2] + image_part[3][0]) / 4\n",
    "        center_comp_sum += (image_part[2][0] + image_part[2][2]) / 2\n",
    "        under_center_comp_sum += image_part[2][1]\n",
    "\n",
    "    if 'grad_ne' in keys:\n",
    "        above_center_comp_sum += (image_part[1][2] + image_part[1][4]) / 2\n",
    "        center_comp_sum += image_part[1][3]\n",
    "        under_center_comp_sum += (image_part[0][3] + image_part[2][3]) / 2\n",
    "\n",
    "    if 'grad_se' in keys:\n",
    "        above_center_comp_sum += (image_part[3][2] + image_part[3][4]) / 2\n",
    "        center_comp_sum += image_part[3][3]\n",
    "        under_center_comp_sum += (image_part[4][3] + image_part[2][3]) / 2\n",
    "\n",
    "    if 'grad_sw' in keys:\n",
    "        above_center_comp_sum += (image_part[3][2] + image_part[3][0]) / 2\n",
    "        center_comp_sum += image_part[3][1]\n",
    "        under_center_comp_sum += (image_part[4][1] + image_part[2][1]) / 2\n",
    "\n",
    "    if 'grad_nw' in keys:\n",
    "        above_center_comp_sum += (image_part[1][0] + image_part[1][2]) / 2\n",
    "        center_comp_sum += image_part[1][1]\n",
    "        under_center_comp_sum += (image_part[0][1] + image_part[2][1]) / 2\n",
    "\n",
    "    above_center_color_comp = image_part[2][2] + (\n",
    "        above_center_comp_sum - center_comp_sum) / len(keys)\n",
    "    under_center_color_comp = image_part[2][2] + (\n",
    "        under_center_comp_sum - center_comp_sum) / len(keys)\n",
    "\n",
    "    above_clipped = min(max_component_value, max(\n",
    "        min_component_value, above_center_color_comp))\n",
    "    under_clipped = min(max_component_value, max(\n",
    "        min_component_value, under_center_color_comp))\n",
    "\n",
    "    return above_clipped, under_clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "novel-religion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:19.793225Z",
     "start_time": "2021-10-21T13:49:19.751539Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_color_components(image_part):\n",
    "    keys = get_direction_keys(image_part)\n",
    "\n",
    "    green_comp_sum = 0\n",
    "    center_comp_sum = 0\n",
    "    side_comp_sum = 0\n",
    "\n",
    "    if 'grad_n' in keys:\n",
    "        green_comp_sum += image_part[1][2]\n",
    "        center_comp_sum += (image_part[0][2] + image_part[2][2]) / 2\n",
    "        side_comp_sum += (image_part[1][1] + image_part[1][3]) / 2\n",
    "\n",
    "    if 'grad_e' in keys:\n",
    "        green_comp_sum += image_part[2][3]\n",
    "        center_comp_sum += (image_part[2][4] + image_part[2][2]) / 2\n",
    "        side_comp_sum += (image_part[3][3] + image_part[1][3]) / 2\n",
    "\n",
    "    if 'grad_s' in keys:\n",
    "        green_comp_sum += image_part[3][2]\n",
    "        center_comp_sum += (image_part[4][2] + image_part[2][2]) / 2\n",
    "        side_comp_sum += (image_part[3][3] + image_part[3][1]) / 2\n",
    "\n",
    "    if 'grad_w' in keys:\n",
    "        green_comp_sum += image_part[2][1]\n",
    "        center_comp_sum += (image_part[2][0] + image_part[2][2]) / 2\n",
    "        side_comp_sum += (image_part[1][1] + image_part[3][1]) / 2\n",
    "\n",
    "    if 'grad_ne' in keys:\n",
    "        green_comp_sum += (image_part[0][3] + image_part[1][2] +\\\n",
    "                           image_part[1][4] + image_part[2][3]) / 4\n",
    "        center_comp_sum += (image_part[0][4] + image_part[2][2]) / 2\n",
    "        side_comp_sum += image_part[1][3]\n",
    "\n",
    "    if 'grad_se' in keys:\n",
    "        green_comp_sum += (image_part[2][3] + image_part[3][2] +\\\n",
    "                           image_part[3][4] + image_part[4][3]) / 4\n",
    "        center_comp_sum += (image_part[4][4] + image_part[2][2]) / 2\n",
    "        side_comp_sum += image_part[3][3]\n",
    "\n",
    "    if 'grad_sw' in keys:\n",
    "        green_comp_sum += (image_part[2][1] + image_part[3][0] +\\\n",
    "                           image_part[3][2] + image_part[4][1]) / 4\n",
    "        center_comp_sum += (image_part[4][0] + image_part[2][2]) / 2\n",
    "        side_comp_sum += image_part[3][1]\n",
    "\n",
    "    if 'grad_nw' in keys:\n",
    "        green_comp_sum += (image_part[0][1] + image_part[1][0] +\\\n",
    "                           image_part[1][2] + image_part[2][1]) / 4\n",
    "        center_comp_sum += (image_part[0][0] + image_part[2][2]) / 2\n",
    "        side_comp_sum += image_part[1][1]\n",
    "\n",
    "    green_comp = image_part[2][2] + (\n",
    "        green_comp_sum - center_comp_sum) / len(keys)\n",
    "    side_comp = image_part[2][2] + (\n",
    "        side_comp_sum - center_comp_sum) / len(keys)\n",
    "\n",
    "    green_clipped = min(max_component_value, max(\n",
    "        min_component_value, green_comp))\n",
    "    side_clipped = min(max_component_value, max(\n",
    "        min_component_value, side_comp))\n",
    "\n",
    "    return green_clipped, side_clipped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-plumbing",
   "metadata": {},
   "source": [
    "Примем во внимание, что сетка может располагаться по-разному относительно изображения. Будем ориентироваться на левый верхний пиксель сетки (пиксель, имеющий координаты $(0,0)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diagnostic-wedding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:22.199638Z",
     "start_time": "2021-10-21T13:49:22.191515Z"
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class CornerColor(Enum):\n",
    "    GREEN_A = 0\n",
    "    RED = 1\n",
    "    BLUE = 2\n",
    "    GREEN_B = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dated-whale",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:24.681825Z",
     "start_time": "2021-10-21T13:49:24.676856Z"
    }
   },
   "outputs": [],
   "source": [
    "def Get_Grid_Corner_Color(image):\n",
    "    upper_left_grid_corner = None\n",
    "\n",
    "    if np.argmax(image[0][0]) == 0:\n",
    "        upper_left_grid_corner = CornerColor.BLUE\n",
    "\n",
    "    if np.argmax(image[0][0]) == 2:\n",
    "        upper_left_grid_corner = CornerColor.RED\n",
    "\n",
    "    if np.argmax(image[0][0]) == 1 and np.argmax(image[0][1]) == 2:\n",
    "        upper_left_grid_corner = CornerColor.GREEN_A\n",
    "\n",
    "    if np.argmax(image[0][0]) == 1 and np.argmax(image[0][1]) == 0:\n",
    "        upper_left_grid_corner = CornerColor.GREEN_B\n",
    "\n",
    "    return upper_left_grid_corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-arizona",
   "metadata": {},
   "source": [
    "Определим, какие индексы (а вернее, их остатки от деления на $2$) будут соответствовать цветам пикселей сетки при различных ее расположениях на изображении.\n",
    "\n",
    "Например, если в левом верхнем углу сетки фильтра расположен красный цвет (как в тестовом изображении), то индексы строки и столбца для пикселей красного цвета фильтра должны быть одновременно четными (т.е. $(0,0)$, $(0,2)$, $(0,4)$, $(2,0)$, $(2,2)$ и т.д.), а синего - нечетными (т.е. $(1,1)$, $(1,3)$, $(1,5)$, $(3,1)$ и т.д.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "incorrect-china",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:26.103879Z",
     "start_time": "2021-10-21T13:49:26.088564Z"
    }
   },
   "outputs": [],
   "source": [
    "green_a_idxs = [(0, 0, CornerColor.GREEN_A), (0, 1, CornerColor.RED),\n",
    "                (1, 0, CornerColor.BLUE), (1, 1, CornerColor.GREEN_B)]\n",
    "red_idxs = [(0, 0, CornerColor.RED), (0, 1, CornerColor.GREEN_A),\n",
    "            (1, 0, CornerColor.GREEN_B), (1, 1, CornerColor.BLUE)]\n",
    "blue_idxs = [(0, 0, CornerColor.BLUE), (0, 1, CornerColor.GREEN_B),\n",
    "            (1, 0, CornerColor.GREEN_A), (1, 1, CornerColor.RED)]\n",
    "green_b_idxs = [(0, 0, CornerColor.GREEN_B), (0, 1, CornerColor.BLUE),\n",
    "                (1, 0, CornerColor.RED), (1, 1, CornerColor.GREEN_A)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-shore",
   "metadata": {},
   "source": [
    "Чтобы для любого пикселя изображения можно было выделить окружающую его область размера $5 \\times 5$, поместим изображение в рамку толщины $2$, каждый пиксель которой в качестве значения цвета имеет максимальное значение компоненты, соответствующей сетке, продолженной с изображения на рамку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "otherwise-democrat",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T13:49:30.411548Z",
     "start_time": "2021-10-21T13:49:30.384956Z"
    }
   },
   "outputs": [],
   "source": [
    "def VNG_algorithm(image):\n",
    "    image = image.astype(np.int32)\n",
    "\n",
    "    upper_left_grid_corner = Get_Grid_Corner_Color(image)\n",
    "\n",
    "    image = np.max(image, axis=2)\n",
    "\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "\n",
    "    blue = np.zeros(image.shape)\n",
    "    green = np.zeros(image.shape)\n",
    "    red = np.zeros(image.shape)\n",
    "\n",
    "    padded_image = np.full((height + 4, width + 4), max_component_value)\n",
    "    padded_image[2:-2, 2:-2] = image\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            image_part = padded_image[i:i+5, j:j+5]\n",
    "            idxs_with_corner = (i % 2, j % 2, upper_left_grid_corner)\n",
    "\n",
    "            if idxs_with_corner in green_a_idxs:\n",
    "                green[i][j] = image[i][j]\n",
    "                blue[i][j], red[i][j] = count_blue_red_components(image_part)\n",
    "            elif idxs_with_corner in red_idxs:\n",
    "                red[i][j] = image[i][j]\n",
    "                green[i][j], blue[i][j] = count_color_components(image_part)\n",
    "            elif idxs_with_corner in blue_idxs:\n",
    "                blue[i][j] = image[i][j]\n",
    "                green[i][j], red[i][j] = count_color_components(image_part)\n",
    "            elif idxs_with_corner in green_b_idxs:\n",
    "                green[i][j] = image[i][j]\n",
    "                red[i][j], blue[i][j] = count_blue_red_components(image_part)\n",
    "\n",
    "    final_image = np.transpose(np.array([blue, green, red]), (1, 2, 0)).astype('uint8')\n",
    "\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-domain",
   "metadata": {},
   "source": [
    "Восстановим тестовое изображение с помощью реализованного алгоритма и запишем его в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "improving-container",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:04:28.713997Z",
     "start_time": "2021-10-21T13:49:33.377152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 53s, sys: 335 ms, total: 14min 53s\n",
      "Wall time: 14min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = VNG_algorithm(rgb_cfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "genetic-gabriel",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:04:31.880395Z",
     "start_time": "2021-10-21T14:04:31.768706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('Result.bmp', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "transsexual-cleaner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:04:37.755523Z",
     "start_time": "2021-10-21T14:04:34.419974Z"
    }
   },
   "outputs": [],
   "source": [
    "viewImage(result, 'Result.bmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-tokyo",
   "metadata": {},
   "source": [
    "Разрешение исходного изображения: $299.875$ пиксели/дюйм.\n",
    "\n",
    "Разрешение восстановленного изображения: $72.000$ пиксели/дюйм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accepting-rates",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:04:40.995001Z",
     "start_time": "2021-10-21T14:04:40.990496Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разрешение восстановленного изображения по сравнению с оригиналом меньше в 4.165 раз.\n"
     ]
    }
   ],
   "source": [
    "ratio = round(299.875 / 72., 3)\n",
    "print(\"Разрешение восстановленного изображения по сравнению с оригиналом меньше в {} раз.\".format(ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-salmon",
   "metadata": {},
   "source": [
    "Вычислим метрику `PSNR` между оригиналом и полученным изображением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "motivated-oxford",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:04:45.803361Z",
     "start_time": "2021-10-21T14:04:45.781722Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE(orig_img, result):\n",
    "    coefs = np.array([0.114, 0.587, 0.299])\n",
    "    orig_y = np.sum(orig_img.astype(np.int32) * coefs, axis=2)\n",
    "    result_y = np.sum(result.astype(np.int32) * coefs, axis=2)\n",
    "    mse = np.sum(np.square(orig_y - result_y)) / (result.shape[0] * result.shape[1])\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "civilian-typing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:04:47.985188Z",
     "start_time": "2021-10-21T14:04:47.967648Z"
    }
   },
   "outputs": [],
   "source": [
    "def psnr(orig_img, result):\n",
    "    y_max = 255.\n",
    "    mse = MSE(orig_img, result)\n",
    "    psnr = 10. * np.log10(y_max ** 2 / mse)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fatal-jesus",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:05:06.068539Z",
     "start_time": "2021-10-21T14:05:05.540434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR между оригиналом и полученным изображением = 26.06088277198723.\n"
     ]
    }
   ],
   "source": [
    "print(\"PSNR между оригиналом и полученным изображением = {}.\".format(psnr(orig_img, result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-chester",
   "metadata": {},
   "source": [
    "Оценим время работы алгоритма в единицах измерения сек/мегапиксель. Время работы в секундах было посчитано выше, оно равно $895$ секундам ($14$ минут $55$ секунд)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "about-maine",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-21T14:05:45.682949Z",
     "start_time": "2021-10-21T14:05:45.667673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Время работы алгоритма: 103.386 сек/мегапиксель.\n"
     ]
    }
   ],
   "source": [
    "time = round(895 / (result.shape[0] * result.shape[1] / 1e6), 3)\n",
    "print(\"Время работы алгоритма: {} сек/мегапиксель.\".format(time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mipt-stats] *",
   "language": "python",
   "name": "conda-env-mipt-stats-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
